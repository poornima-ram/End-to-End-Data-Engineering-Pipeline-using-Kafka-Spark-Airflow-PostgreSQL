# End-to-End-Data-Engineering-Pipeline-using-Kafka-Spark-Airflow-PostgreSQL
Designed and implemented an end-to-end data engineering pipeline that ingests real-time data via Kafka, processes it using Apache Spark, orchestrates workflows with Apache Airflow, and persists transformed data into PostgreSQL. The entire system is containerized using Docker for reproducibility and scalability.
